OpenMM: An Open-source Multimodal Feature Extraction Tool
=============

This repo represents the code for my dissertation work. The goal of this repo is to release an open-source tool, which can perform multimodal feature extraction. In other words, this tool will allow you to easily extract video, audio, and linguistic features all at once. This tool builds upon existing repos for visual feature extraction [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace) and audio feature extraction [Covarep](https://github.com/covarep/covarep). I combine these existing repos with my code for linguistic feature extraction. OpenMM provides a simple way for researchers to extract multimodal features. The tool only requires a video as input and outputs a csv of multimodal features, audio conversion and speech-to-text are handled internally. My hope is that this will help promote more interest and research in building multimodal systems. 

![alt tag](https://github.com/michellemorales/OpenMM/blob/master/images/PipelineVersion3.jpeg)
